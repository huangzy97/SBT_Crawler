# -*- coding: utf-8 -*-
"""
Created on Wed May 22 09:47:57 2019

@author: sbtithzy
"""
import os
os.environ['NLS_LANG'] = 'SIMPLIFIED CHINESE_CHINA.UTF8'
import time
start = time.clock()
import urllib2, re, requests, HTMLParser
import cx_Oracle
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'}
######################连接oracle
print('连接到oracle数据库...')
conn = cx_Oracle.connect('用户名/密码@主机地址/数据库')###OA数据库 
print('数据库连接成功!')
cur = conn.cursor()
###获取最大ID
sql1 = """select nvl(max(id),0) from picture"""
Id = cur.execute(sql1)
li =Id.fetchall()
###存入最大ID
IdMax = li[0][0]
conn.commit()
#清空表数据
cur.execute("Truncate TABLE picture")
#########################
# 获取网站信息
#url = 'http://www.sobute.com/index.php/news.html'                 
def getHtml(url):
    req = urllib2.Request(url)
    req.headers = headers
    res = urllib2.urlopen(req)  # 打开网页
    text = res.read()
    return text
# 提取新闻地址
def getUrls(url):
    html = getHtml(url)
    pattern = re.compile('<li class="item">(.*?) class="clear">',re.S)
    items = re.findall(pattern, html)
    urls = []
    for item in items:
        urls.append(item[-50:-1])
    return urls
PICTUREORDER = [1,2,3,4,5,6,7,8]
ID = [IdMax+1,IdMax+2,IdMax+3,IdMax+4,IdMax+5,IdMax+6,IdMax+7,IdMax+8]
def getContent(url): 
    global i
    html = getHtml(url)
    pattern = re.compile('<h1>(.*?)</h1>')####文章标题 
    pattern2 = re.compile('<img src="(.*?)" title="')######提取照片地址 
    items = re.findall(pattern, html)
    items2 = re.findall(pattern2, html)
####保存数据  
    result = []
    result = [ID[i],items2[0],items[0],url,PICTUREORDER[i],2,132] 
    cur.execute("INSERT INTO picture(ID,PICTUREURL,PICTURENAME,PICTURELINK,\
                                        PICTUREORDER,PICTURETYPE,EID) \
                VALUES ('%s','%s','%s','%s','%s','%s','%s')" % (ID[i],items2[0],items[0],url,PICTUREORDER[i],2,132))
    conn.commit()
#定义一个全局变量
i = 0
def main():    
    urls = ['http://www.sobute.com/index.php/news.html']    
    print u'开始写入数据库，请稍等...'
    x = 0    
    for url in urls:
        html = getHtml(url)    
        for url in getUrls(url):  
            try:            
                getContent(url)
                global i
                x = x + 1
                i = i + 1
            except Exception,e:
                print e                
    print u'累计写入数据%s条'%(x)
    print u'数据存储结束！'
if __name__ == "__main__":  # 判断文件入口
    main()
elapsed = (time.clock() - start)#####时间结束点
print u'累计用时:',elapsed #####累计用时
